# zoroRH - Backend 

**Solution IA pour la R√©tention des Talents RH**

![Python](https://img.shields.io/badge/Python-3.11+-3776AB?style=flat&logo=python&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-009688?style=flat&logo=fastapi&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-4169E1?style=flat&logo=postgresql&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?style=flat&logo=docker&logoColor=white)
![ML](https://img.shields.io/badge/ML-scikit--learn-F7931E?style=flat&logo=scikit-learn&logoColor=white)

---

## Description

**zoroRH** est une application backend intelligente destin√©e aux √©quipes **Ressources Humaines** pour **anticiper les d√©parts volontaires** et **proposer automatiquement des plans de r√©tention personnalis√©s**.

### Le Syst√®me Combine

| Machine Learning |  API S√©curis√©e |  IA G√©n√©rative |
|---------------------|------------------|------------------|
| Pr√©diction risque d√©part | Auth JWT + PostgreSQL | Plans personnalis√©s |
| Random Forest optimis√© | Tra√ßabilit√© compl√®te | Google Gemini AI |

---

##  Objectifs

### Business
- ‚úÖ Identifier les profils √† **haut risque de d√©mission**
- ‚úÖ R√©duire le **turnover** et pr√©server les talents cl√©s
- ‚úÖ Automatiser l'analyse RH et les recommandations
- ‚úÖ D√©cisions **objectives et personnalis√©es**

### Techniques
- ‚úÖ Pipeline **ML supervis√©** (Random Forest)
- ‚úÖ API **REST FastAPI** s√©curis√©e
- ‚úÖ Authentification **JWT**
- ‚úÖ Base **PostgreSQL** tra√ßable
- ‚úÖ IA g√©n√©rative **Gemini**
- ‚úÖ **Docker** pour d√©ploiement reproductible

---

##  Fonctionnalit√©s

###  Authentification
- **Inscription** : `POST /register` (hashage bcrypt)
- **Connexion** : `POST /login` (token JWT)
- **Protection** : Middleware JWT sur routes m√©tier

###  Machine Learning
- **Pr√©diction** : `POST /predict`
  - Probabilit√© churn 0-100%
  - Niveau risque : LOW/MEDIUM/HIGH
  - Mod√®le Random Forest optimis√©

###  IA G√©n√©rative
- **Plans r√©tention** : `POST /generate-retention-plan`
  - D√©clenchement si probabilit√© > 50%
  - Recommandations personnalis√©es (Gemini AI)
  - Actions concr√®tes pour managers RH

###  Gestion Donn√©es
- **Liste employ√©s** : `GET /employees`
- **Historique pr√©dictions** : Tra√ßabilit√© PostgreSQL

---

##  Architecture
```
Client RH (Frontend)
        ‚Üì JWT Token
FastAPI Backend
  ‚îú‚îÄ Auth (JWT)
  ‚îú‚îÄ Routes API
  ‚îú‚îÄ ML Service (modele_attrition_best.pkl)
  ‚îî‚îÄ IA Service (Gemini)
        ‚Üì
PostgreSQL + Google Gemini AI
```

---

##  Structure du Projet
```
RETENTIONAI-BACKEND/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ auth/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ token_auth.py              # JWT logic
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.py                  # Variables env
‚îÇ   ‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data.csv                   # Dataset ML
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ db_connection.py           # SQLAlchemy
‚îÇ   ‚îú‚îÄ‚îÄ models/                        # ORM Models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ employee.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ history.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ user.py
‚îÇ   ‚îú‚îÄ‚îÄ routes/                        # API Endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ login_router.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ register_router.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prediction_router.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ retention_router.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ get_all_employees_router.py
‚îÇ   ‚îú‚îÄ‚îÄ schemas/                       # Pydantic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ LoginRequest_schema.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SignupRequest_schema.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ PredictRequest_schema.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ retention_schema.py
‚îÇ   ‚îú‚îÄ‚îÄ services/                      # Business Logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gemini_retention_service.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ modele_attrition_best.pkl  # ML Model
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ml_service.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_model.py
‚îÇ   ‚îî‚îÄ‚îÄ main.py                        # Entry point
‚îÇ
‚îú‚îÄ‚îÄ .env                               # Secrets (not versioned)
‚îú‚îÄ‚îÄ .env.example                       # Template
‚îú‚îÄ‚îÄ docker-compose.yml                 # Docker orchestration
‚îú‚îÄ‚îÄ Dockerfile                         # Backend image
‚îú‚îÄ‚îÄ init.sql                           # DB init script
‚îú‚îÄ‚îÄ requirements.txt                   # Dependencies
‚îî‚îÄ‚îÄ README.md
```

---

##  Technologies

| Cat√©gorie | Stack |
|-----------|-------|
| **Backend** | FastAPI 0.104+, Uvicorn, Pydantic |
| **ML** | scikit-learn, pandas, numpy, seaborn |
| **IA** | Google Generative AI (Gemini) |
| **Database** | PostgreSQL 15, SQLAlchemy, psycopg2 |
| **Auth** | JWT (python-jose), bcrypt |
| **DevOps** | Docker, Docker Compose, pytest |

---

##  Installation

### Pr√©requis
- Python 3.11+
- PostgreSQL 15+
- [Cl√© API Google Gemini](https://makersuite.google.com/app/apikey)
- Docker & Docker Compose (optionnel)

### Installation Locale
```bash
# 1. Cloner le repo
git clone https://github.com/votre-username/zororh-backend.git
cd zororh-backend

# 2. Environnement virtuel
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows

# 3. D√©pendances
pip install -r requirements.txt

# 4. Variables d'environnement
cp .env.example .env
# √âditer .env avec vos valeurs
```

### Configuration `.env`
```env
# Google Gemini
GEMINI_API_KEY=your_gemini_api_key

# PostgreSQL
DB_HOST=localhost
DB_PORT=5432
DB_NAME=retentionai_db
DB_USER=retention_user
DB_PASSWORD=your_password

# JWT
SECRET_KEY=your_secret_key_32_chars
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=1440

# Environment
ENVIRONMENT=development
```

**G√©n√©rer SECRET_KEY :**
```bash
openssl rand -hex 32
```

### Initialiser la Database
```bash
# Cr√©er la DB
psql -U postgres -f init.sql

# Ou manuellement :
psql -U postgres
CREATE DATABASE retentionai_db;
\c retentionai_db
# Copier le contenu de init.sql
```

### Lancer le Serveur
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

 API accessible sur : **http://localhost:8000**  
 Documentation : **http://localhost:8000/docs**

---

##  Installation Docker (Recommand√©)
```bash
# Cr√©er .env
cp .env.example .env

# Lancer tout (PostgreSQL + Backend)
docker-compose up -d

# Logs
docker-compose logs -f

# Arr√™ter
docker-compose down
```

‚úÖ **PostgreSQL** : port 5432  
‚úÖ **FastAPI** : port 8000

---

##  Documentation API

### Base URL
- **Local** : `http://localhost:8000`
- **Docs** : `http://localhost:8000/docs`

---

###  Authentification

#### `POST /register`

**Body :**
```json
{
  "username": "hr_manager",
  "password": "SecurePass123!"
}
```

**Response (201) :**
```json
{
  "message": "Utilisateur cr√©√© avec succ√®s",
  "access_token": "eyJhbGci...",
  "token_type": "bearer"
}
```

---

#### `POST /login`

**Body :**
```json
{
  "username": "hr_manager",
  "password": "SecurePass123!"
}
```

**Response (200) :**
```json
{
  "access_token": "eyJhbGci...",
  "token_type": "bearer",
  "username": "hr_manager"
}
```

---

###  Machine Learning (Prot√©g√© üîí)

#### `POST /predict`

**Headers :**
```
Authorization: Bearer your_jwt_token
```

**Body :**
```json
{
  "Age": 35,
  "Department": "Sales",
  "JobRole": "Sales Executive",
  "MonthlyIncome": 5000,
  "YearsAtCompany": 7,
  "JobSatisfaction": 3,
  "WorkLifeBalance": 2,
  "OverTime": "Yes",
  "DistanceFromHome": 15,
  "NumCompaniesWorked": 2
}
```

**Response (200) :**
```json
{
  "employee_id": 12345,
  "churn_probability": 0.78,
  "risk_level": "HIGH",
  "message": "Risque √©lev√© de d√©part d√©tect√©"
}
```

**Niveaux de risque :**
- `0-30%` ‚Üí LOW
- `30-50%` ‚Üí MEDIUM
- `50-100%` ‚Üí HIGH

---

#### `POST /generate-retention-plan`

 D√©clench√© seulement si **probabilit√© > 50%**

**Headers :**
```
Authorization: Bearer your_jwt_token
```

**Body :**
```json
{
  "employee_data": {
    "Age": 35,
    "Department": "Sales",
    "JobRole": "Sales Executive",
    "MonthlyIncome": 5000,
    "YearsAtCompany": 7,
    "JobSatisfaction": 3,
    "WorkLifeBalance": 2,
    "OverTime": "Yes",
    "DistanceFromHome": 15
  },
  "churn_probability": 0.78
}
```

**Response (200) :**
```json
{
  "retention_plan": "1. Proposer 2 jours t√©l√©travail\n2. R√©√©valuer d√©placements\n3. Formation personnalis√©e\n4. Entretien individuel prioritaire",
  "risk_level": "HIGH",
  "generated_at": "2025-12-19T14:30:00Z"
}
```

---

###  Gestion Donn√©es

#### `GET /employees`

**Headers :**
```
Authorization: Bearer your_jwt_token
```

**Query Params (optionnel) :**
- `department` : Filtrer par d√©partement
- `limit` : Nombre max r√©sultats (d√©faut: 100)

**Response (200) :**
```json
{
  "employees": [
    {
      "id": 1,
      "age": 35,
      "department": "Sales",
      "job_role": "Sales Executive",
      "monthly_income": 5000
    }
  ],
  "total": 1
}
```

---

##  Machine Learning Pipeline

### 1. Analyse Exploratoire (EDA)
```python
import pandas as pd
import seaborn as sns

df = pd.read_csv('app/db/data.csv')

# Corr√©lations
sns.heatmap(df.corr(), annot=True)

# Distribution
sns.countplot(data=df, x='Attrition')
```

**Insights :**
- Variables cl√©s : `OverTime`, `JobSatisfaction`, `WorkLifeBalance`
- D√©s√©quilibre : ~16% attrition

---

### 2. Preprocessing
```python
from sklearn.preprocessing import StandardScaler, OneHotEncoder

# Features
numeric = ['Age', 'MonthlyIncome', 'YearsAtCompany']
categorical = ['Department', 'JobRole', 'OverTime']

# Pipeline
preprocessor = ColumnTransformer([
    ('num', StandardScaler(), numeric),
    ('cat', OneHotEncoder(drop='first'), categorical)
])
```

---

### 3. Entra√Ænement
```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# GridSearch
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [10, 20, None]
}

grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)
grid.fit(X_train, y_train)
best_model = grid.best_estimator_
```


---

### 4. Sauvegarde
```python
import pickle

with open('modele_attrition_best.pkl', 'wb') as f:
    pickle.dump(best_model, f)
```

---

##  IA G√©n√©rative - Gemini

### Prompt Template
```python
prompt = f"""
Tu es un expert RH. Voici les infos employ√© :

- √Çge : {age}
- D√©partement : {department}
- R√¥le : {job_role}
- Satisfaction : {job_satisfaction}/4
- Work-Life Balance : {work_life_balance}/4
- Heures sup : {overtime}
- Distance : {distance_from_home} km

Risque d√©part ML : {churn_probability*100:.1f}%

Propose 3-4 actions concr√®tes pour le retenir.
Format : op√©rationnel pour manager RH.
"""
```

### Exemple R√©ponse
```
1. Proposer 2 jours t√©l√©travail/semaine
2. R√©√©valuer charge d√©placements (15km)
3. Formation certifiante management
4. Entretien individuel sous 7 jours
```

---

##  Base de Donn√©es

### Sch√©ma
```sql
-- Users
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    username VARCHAR(100) UNIQUE NOT NULL,
    password VARCHAR(255) NOT NULL,
    created_at TIMESTAMP DEFAULT NOW()
);

-- Employees
CREATE TABLE employees (
    id SERIAL PRIMARY KEY,
    age INTEGER,
    department VARCHAR(100),
    job_role VARCHAR(100),
    monthly_income INTEGER,
    years_at_company INTEGER,
    job_satisfaction INTEGER CHECK (job_satisfaction BETWEEN 1 AND 4),
    work_life_balance INTEGER CHECK (work_life_balance BETWEEN 1 AND 4),
    overtime VARCHAR(10),
    distance_from_home INTEGER
);

-- Predictions History
CREATE TABLE predictions_history (
    id SERIAL PRIMARY KEY,
    timestamp TIMESTAMP DEFAULT NOW(),
    user_id INTEGER REFERENCES users(id),
    employee_id INTEGER,
    probability FLOAT CHECK (probability BETWEEN 0 AND 1),
    risk_level VARCHAR(20),
    retention_plan TEXT
);
```

---

##  Tests
```bash
# Tous les tests
pytest app/tests/ -v

# Avec couverture
pytest app/tests/ --cov=app

# Tests sp√©cifiques
pytest app/tests/test_model.py -v
```

### Exemple Test
```python
def test_model_loading():
    with open('app/services/modele_attrition_best.pkl', 'rb') as f:
        model = pickle.load(f)
    assert model is not None

def test_prediction():
    sample = {"Age": 35, "Department": "Sales", "MonthlyIncome": 5000}
    prediction = model.predict_proba([sample])[0][1]
    assert 0 <= prediction <= 1
```

---

## Exemples Utilisation

### cURL
```bash
# Inscription
curl -X POST http://localhost:8000/register \
  -H "Content-Type: application/json" \
  -d '{"username":"test","password":"test123"}'

# Connexion
curl -X POST http://localhost:8000/login \
  -H "Content-Type: application/json" \
  -d '{"username":"test","password":"test123"}'

# Pr√©diction
TOKEN="your_jwt_token"
curl -X POST http://localhost:8000/predict \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "Age": 35,
    "Department": "Sales",
    "JobRole": "Sales Executive",
    "MonthlyIncome": 5000,
    "YearsAtCompany": 7,
    "JobSatisfaction": 3,
    "WorkLifeBalance": 2,
    "OverTime": "Yes",
    "DistanceFromHome": 15,
    "NumCompaniesWorked": 2
  }'
```

---

### Python
```python
import requests

BASE_URL = "http://localhost:8001"

# Login
r = requests.post(f"{BASE_URL}/login", json={
    "username": "test", "password": "test123"
})
token = r.json()["access_token"]

# Predict
headers = {"Authorization": f"Bearer {token}"}
data = {
    "Age": 35, "Department": "Sales",
    "JobRole": "Sales Executive",
    "MonthlyIncome": 5000,
    "YearsAtCompany": 7,
    "JobSatisfaction": 3,
    "WorkLifeBalance": 2,
    "OverTime": "Yes",
    "DistanceFromHome": 15,
    "NumCompaniesWorked": 2
}

result = requests.post(f"{BASE_URL}/predict", json=data, headers=headers)
print(f"Risque : {result.json()['churn_probability']*100:.1f}%")
```

---

##  S√©curit√©

- **JWT** : Tokens expirables (24h)
- **Bcrypt** : Hashage mots de passe
- **CORS** : Configurer origines autoris√©es en production
- **SQL Injection** : Protection via ORM SQLAlchemy
- **Validation** : Pydantic sur toutes les entr√©es

---

##  Liens Utiles

- [FastAPI Docs](https://fastapi.tiangolo.com/)
- [PostgreSQL Tutorial](https://www.postgresqltutorial.com/)
- [Gemini AI Docs](https://ai.google.dev/docs)
- [scikit-learn Guide](https://scikit-learn.org/stable/user_guide.html)
